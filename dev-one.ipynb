{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jisoo/.conda/envs/dev/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "from open_flamingo import create_model_and_transforms\n",
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_NUM = 0\n",
    "# SAMPLE_SIZE = 24\n",
    "# NUM_TRIALS = 1\n",
    "DATASET_NAME = 'idoll_man'\n",
    "SORT_KEY = 'choice_rate'\n",
    "MODEL_SIZE = '9B'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './'\n",
    "datasets = {}\n",
    "\n",
    "with open(os.path.join(root_dir, 'Dataset00.pkl'), 'rb') as f:\n",
    "    idoll_man = pickle.load(f)\n",
    "datasets['idoll_man'] = idoll_man\n",
    "\n",
    "with open(os.path.join(root_dir, 'Dataset01.pkl'), 'rb') as f:\n",
    "    idoll_woman = pickle.load(f)\n",
    "datasets['idoll_woman'] = idoll_woman\n",
    "\n",
    "with open(os.path.join(root_dir, 'Dataset02.pkl'), 'rb') as f:\n",
    "    paintings = pickle.load(f)\n",
    "datasets['paintings'] = paintings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_bins(sorted_list, sample_size):\n",
    "    # Create bins from the sorted list\n",
    "    bin_size = max(1, math.ceil(len(sorted_list) / sample_size))\n",
    "    bins = [sorted_list[i:i + bin_size] for i in range(0, len(sorted_list), bin_size)]\n",
    "    return bins\n",
    "\n",
    "def sample_from_bins(bins):\n",
    "    # Randomly select one element from each bin\n",
    "    return [random.choice(bin) for bin in bins if bin]\n",
    "\n",
    "def shuffle_samples_with_indices(samples):\n",
    "    indexed_samples = list(enumerate(samples))\n",
    "    random.shuffle(indexed_samples)\n",
    "    shuffled_samples, indices = zip(*indexed_samples)\n",
    "    return list(shuffled_samples), list(indices)\n",
    "\n",
    "def sort_once_sample_shuffle_multiple_trials(tuple_list, sort_key, reverse, sample_size, trials):\n",
    "    \"\"\"\n",
    "    Example usage\n",
    "    \n",
    "    tuple_list = [\n",
    "        (1, \"http://example.com\", \"classA\", '10.00%', '15.00%'),\n",
    "        (2, \"http://example.org\", \"classB\", '5.50%', '20.00%'),\n",
    "        (3, \"http://example.net\", \"classC\", '8.75%', '12.00%'),\n",
    "    Outputs = sort_once_sample_shuffle_multiple_trials(tuple_list, 'win_rate', True, 2, 3)\n",
    "\n",
    "    Outputs: \n",
    "        [\n",
    "            ([1, 0],\n",
    "             [(2, 'http://example.org', 'classB', '5.50%', '20.00%'),\n",
    "             (1, 'http://example.com', 'classA', '10.00%', '15.00%')]),\n",
    "            ([1, 0],\n",
    "             [(2, 'http://example.org', 'classB', '5.50%', '20.00%'),\n",
    "             (1, 'http://example.com', 'classA', '10.00%', '15.00%')]),\n",
    "            ([1, 0],\n",
    "             [(2, 'http://example.org', 'classB', '5.50%', '20.00%'),\n",
    "             (3, 'http://example.net', 'classC', '8.75%', '12.00%')\n",
    "        ]\n",
    "    \"\"\"\n",
    "    if sort_key not in {'win_rate', 'choice_rate'}:\n",
    "        raise ValueError(\"sort_key must be 'win_rate' or 'choice_rate'\")\n",
    "\n",
    "    if sample_size < 1 or sample_size > len(tuple_list):\n",
    "        raise ValueError(\"sample_size must be between 1 and the length of tuple_list\")\n",
    "\n",
    "    # Function to convert percentage string to float\n",
    "    def convert_to_float(percentage_str):\n",
    "        return float(percentage_str.rstrip('%'))\n",
    "\n",
    "    # Determine the index for win_rate or choice_rate in the tuple\n",
    "    index = 3 if sort_key == 'win_rate' else 4\n",
    "\n",
    "    # Sort the list of tuples based on the specified index\n",
    "    sorted_list = sorted(tuple_list, key=lambda x: convert_to_float(x[index]), reverse=reverse)\n",
    "\n",
    "    # Create bins from the sorted list\n",
    "    bins = create_bins(sorted_list, sample_size)\n",
    "\n",
    "    results = []\n",
    "    for _ in range(trials):\n",
    "        # Sample from the bins bfor each trial\n",
    "        sample = sample_from_bins(bins)\n",
    "        shuffled_sample, original_indices = shuffle_samples_with_indices(sample)\n",
    "        results.append((shuffled_sample, original_indices))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using config.init_device='cpu', but you can also use config.init_device=\"meta\" with Composer + FSDP for fast initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:17<00:00,  5.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flamingo model initialized with 1384781840 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if MODEL_SIZE == '3B':\n",
    "    model, image_processor, tokenizer = create_model_and_transforms(\n",
    "        clip_vision_encoder_path=\"ViT-L-14\",\n",
    "        clip_vision_encoder_pretrained=\"openai\",\n",
    "        lang_encoder_path=\"anas-awadalla/mpt-1b-redpajama-200b\",\n",
    "        tokenizer_path=\"anas-awadalla/mpt-1b-redpajama-200b\",\n",
    "        cross_attn_every_n_layers=1\n",
    "    )\n",
    "\n",
    "    checkpoint_path = hf_hub_download(\"openflamingo/OpenFlamingo-3B-vitl-mpt1b\", \"checkpoint.pt\")\n",
    "    model.load_state_dict(torch.load(checkpoint_path), strict=False)\n",
    "    model = model.to(DEVICE_NUM)\n",
    "elif MODEL_SIZE == '9B':\n",
    "    model, image_processor, tokenizer = create_model_and_transforms(\n",
    "        clip_vision_encoder_path=\"ViT-L-14\",\n",
    "        clip_vision_encoder_pretrained=\"openai\",\n",
    "        lang_encoder_path=\"anas-awadalla/mpt-7b\",\n",
    "        tokenizer_path=\"anas-awadalla/mpt-7b\",\n",
    "        cross_attn_every_n_layers=4\n",
    "    )\n",
    "\n",
    "    checkpoint_path = hf_hub_download(\"openflamingo/OpenFlamingo-9B-vitl-mpt7b\", \"checkpoint.pt\")\n",
    "    model.load_state_dict(torch.load(checkpoint_path), strict=False)\n",
    "    # model = model.to(DEVICE_NUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 26, 18, 46, 23, 19, 50, 35, 45, 0, 12, 14, 41, 22, 11, 40, 36, 44, 30, 47, 13, 1, 3, 17, 34, 5, 54, 32, 49, 51, 6, 42, 21, 9, 43, 27, 2, 53, 28, 38, 8, 4, 33, 31, 29, 7, 37, 20, 10, 15, 39, 52, 48, 16, 24]\n",
      "55\n",
      "([25, 26, 18, 46, 23, 19, 50, 35, 45, 0, 12, 14, 41, 22, 11, 40, 36, 44, 30, 47, 13, 1, 3, 17, 34, 5, 54, 32, 49, 51, 6, 42, 21, 9, 43, 27, 2, 53, 28, 38, 8, 4, 33, 31, 29, 7, 37, 20, 10, 15, 39, 52, 48, 16, 24], [('146', 'https://img.piku.co.kr/w/uploads/721FCA/df4371e33070bf6d9dc28edfb26b14fb.jpg', '데이식스 도운', '0.38%', '46.33%'), ('91', 'https://img.piku.co.kr/w/uploads/721FCA/248d47a168cfb9374b061d7f353437db.jpg', '방탄 RM', '0.98%', '45.61%'), ('154', 'https://img.piku.co.kr/w/uploads/721FCA/f1f9acc8a482fcb41c644847be327599.jpg', '엑소 시우민', '0.35%', '52.35%'), ('257', 'https://img.piku.co.kr/w/uploads/721FCA/752d18a54fe08fb7f8aaadb1e1a45757.jpg', '템페스트 한빈', '0.04%', '31.48%'), ('131', 'https://img.piku.co.kr/w/uploads/721FCA/350c346668d343bca07002cfebc7a26b.jpg', '판타지보이즈 김우석', '0.47%', '47.87%'), ('134', 'https://img.piku.co.kr/w/uploads/721FCA/8bd1ff530031b81220de9eef93a685a4.jpg', '샤이니 온유', '0.45%', '51.08%'), ('219', 'https://img.piku.co.kr/w/uploads/721FCA/754c1acfeb3098940e4f3db463f5034a.jpg', '비투비 서은광', '0.13%', '25.48%'), ('169', 'https://img.piku.co.kr/w/uploads/721FCA/7a67aba85017a8359a811dfb14b48d8d.jpg', 'WayV 텐', '0.30%', '41.55%'), ('263', 'https://img.piku.co.kr/w/uploads/721FCA/06a898e9159d108d82e79b3cd5f9088c.jpg', '펜타곤 우석', '0.02%', '31.97%'), ('1', 'https://img.piku.co.kr/w/uploads/721FCA/9d4291f0483b58bf3f1ecd0ee17d40c4.jpg', '아스트로 차은우', '11.31%', '77.56%'), ('83', 'https://img.piku.co.kr/w/uploads/721FCA/246dab1448c88e2c6d4c89e5a980cf00.jpg', '크래비티 구정모', '1.13%', '59.02%'), ('55', 'https://img.piku.co.kr/w/uploads/721FCA/a1716c9453c4bb62f959fd0bd615ab8f.jpg', 'NCT 드림 제노', '1.86%', '57.58%'), ('248', 'https://img.piku.co.kr/w/uploads/721FCA/bf73e64508a5893766dc757cbdb9d6ce.jpg', '온앤오프 효진', '0.06%', '36.56%'), ('130', 'https://img.piku.co.kr/w/uploads/721FCA/a85b82f7514d3a57df5477d9eaf25869.jpg', 'NCT 127 유타', '0.50%', '49.43%'), ('70', 'https://img.piku.co.kr/w/uploads/721FCA/c3e2ce85d23775aa2e4f4ddc1552a865.jpg', 'WayV 윈윈', '1.36%', '59.95%'), ('243', 'https://img.piku.co.kr/w/uploads/721FCA/b4cc4c93ea6d7d1ad3cef560c5e39e97.jpg', '골든차일드 Y', '0.07%', '36.80%'), ('197', 'https://img.piku.co.kr/w/uploads/721FCA/67e23c57fdbfb354ec7aff6df6c170d4.jpg', '유나이트 이은상', '0.19%', '39.86%'), ('228', 'https://img.piku.co.kr/w/uploads/721FCA/4acbf49278acd1e42b1846ffb53fd9cf.jpg', '하이라이트 양요섭', '0.11%', '32.98%'), ('156', 'https://img.piku.co.kr/w/uploads/721FCA/9a8c683e855fa9584ceb6f3256c004f5.jpg', 'DKZ 재찬', '0.34%', '42.93%'), ('210', 'https://img.piku.co.kr/w/uploads/721FCA/c6b07f9b55c27d4bf0b0f3c34d483d72.jpg', '에이티즈 홍중', '0.15%', '30.75%'), ('80', 'https://img.piku.co.kr/w/uploads/721FCA/5da776dbaffaaf82aeee30bcc8035267.jpg', '엔하이픈 희승', '1.21%', '57.93%'), ('15', 'https://img.piku.co.kr/w/uploads/721FCA/8567723d10035cdce711487c94f0f8b0.jpg', '제로베이스원 한유진', '4.51%', '70.44%'), ('22', 'https://img.piku.co.kr/w/uploads/721FCA/b2520a5d1f437e5e09dfcc209a905200.jpg', '박지훈', '3.68%', '67.55%'), ('88', 'https://img.piku.co.kr/w/uploads/721FCA/e9b937211bc321fd1b63a606b9caf64c.jpg', '제로베이스원 리키', '1.07%', '53.77%'), ('222', 'https://img.piku.co.kr/w/uploads/721FCA/a1be74c84769db8c776820d0af958f3c.jpg', '템페스트 혁', '0.11%', '42.15%'), ('37', 'https://img.piku.co.kr/w/uploads/721FCA/7c2587cf032242ef008c64ad95aa1288.jpg', '더보이즈 영훈', '2.75%', '65.77%'), ('261', 'https://img.piku.co.kr/w/uploads/721FCA/4435cfddb1fe0ea3787bec74bf850700.jpg', '드리핀 주창욱', '0.04%', '16.98%'), ('166', 'https://img.piku.co.kr/w/uploads/721FCA/228de5cdf180d9afd5db0c62f31a75c4.jpg', '에이티즈 윤호', '0.31%', '42.53%'), ('212', 'https://img.piku.co.kr/w/uploads/721FCA/481c935af17bf4af1e7f3e41cb97771a.jpg', '에이티즈 민기', '0.15%', '27.71%'), ('254', 'https://img.piku.co.kr/w/uploads/721FCA/43bf98f0b3dd42898a9ff755f9823524.jpg', '온앤오프 MK', '0.06%', '24.36%'), ('20', 'https://img.piku.co.kr/w/uploads/721FCA/fd61a3c7ed91ba0978ba03683903604f.jpg', '스키즈 현진', '3.65%', '64.76%'), ('209', 'https://img.piku.co.kr/w/uploads/721FCA/acabf7c318db8097549af2e5959deb87.jpg', '위너 강승윤', '0.15%', '35.59%'), ('111', 'https://img.piku.co.kr/w/uploads/721FCA/321c39dbeb5d37a5a0dcf33416384637.jpg', 'CIX 현석', '0.65%', '49.81%'), ('48', 'https://img.piku.co.kr/w/uploads/721FCA/67f018185350562113e2370d9da95548.jpg', 'NCT 127 도영', '2.15%', '60.53%'), ('262', 'https://img.piku.co.kr/w/uploads/721FCA/17134118b6a4f447f878c9616b9233b1.jpg', '드리핀 황윤성', '0.02%', '34.69%'), ('240', 'https://img.piku.co.kr/w/uploads/721FCA/eb5bbfe1fafa5bf13bcf576222d0187c.jpg', '베리베리 동헌', '0.08%', '45.39%'), ('16', 'https://img.piku.co.kr/w/uploads/721FCA/3eeaa7b3620296004304e89ce1c8e658.jpg', '비투비 육성재', '4.20%', '69.69%'), ('260', 'https://img.piku.co.kr/w/uploads/721FCA/2933e7d794534f70c58089ea3dc7353c.jpg', '펜타곤 유토', '0.04%', '19.04%'), ('189', 'https://img.piku.co.kr/w/uploads/721FCA/c595b1f93f47d682649522e1a7099198.jpg', '판타지보이즈 소울', '0.21%', '44.85%'), ('187', 'https://img.piku.co.kr/w/uploads/721FCA/f065d01551066dcf82b8928cd62f27d0.jpg', '이븐 박지후', '0.22%', '38.59%'), ('30', 'https://img.piku.co.kr/w/uploads/721FCA/41d092c8b5b1251541bbf506873e3c9f.jpg', '세븐틴 호시', '2.93%', '61.76%'), ('26', 'https://img.piku.co.kr/w/uploads/721FCA/adfcdf12808449604e5e8b1bdf29c469.jpg', '베리베리 강민', '3.17%', '66.75%'), ('180', 'https://img.piku.co.kr/w/uploads/721FCA/414f36889fb2fd14cf6e68244d7c1717.jpg', '위아이 김동한', '0.24%', '42.36%'), ('214', 'https://img.piku.co.kr/w/uploads/721FCA/b93ac5498ec94a6f50470e6a6fc9e9a9.jpg', '에이티즈 종호', '0.13%', '42.84%'), ('190', 'https://img.piku.co.kr/w/uploads/721FCA/e3b241f783a365281927c72846553a21.jpg', '엔플라잉 재현', '0.21%', '43.66%'), ('44', 'https://img.piku.co.kr/w/uploads/721FCA/dcbcbee17b484f1751e70d14b5803d99.jpg', '더보이즈 주연', '2.28%', '62.68%'), ('224', 'https://img.piku.co.kr/w/uploads/721FCA/ee27d8ae05a69dd049e35f94dc20d0b5.jpg', '온앤오프 제이어스', '0.11%', '39.31%'), ('89', 'https://img.piku.co.kr/w/uploads/721FCA/f83200518e8756a585314a7559034cc2.jpg', '엔하이픈 정원', '1.06%', '50.37%'), ('72', 'https://img.piku.co.kr/w/uploads/721FCA/557c3f6e6f3877db151a086844f31b31.jpg', '엔하이픈 성훈', '1.29%', '60.53%'), ('71', 'https://img.piku.co.kr/w/uploads/721FCA/ab964e86cc316d2c134899f9c7c4f1a0.jpg', '엔하이픈 제이크', '1.38%', '57.23%'), ('170', 'https://img.piku.co.kr/w/uploads/721FCA/604fcc228f2c333f9b7e609536ad2fbd.jpg', '크래비티 함원진', '0.30%', '38.21%'), ('266', 'https://img.piku.co.kr/w/uploads/721FCA/4ed626165e14ae51ddf47a5eb67f04b5.jpg', '갓세븐 유겸', '0.02%', '22.05%'), ('185', 'https://img.piku.co.kr/w/uploads/721FCA/10b75af86d3b64d2fd88d5766483a8ab.jpg', '판타지보이즈 케이단', '0.23%', '28.60%'), ('65', 'https://img.piku.co.kr/w/uploads/721FCA/b6c31abe06b84c283d3e9fb00a479e17.jpg', '몬스타엑스 기현', '1.42%', '54.87%'), ('112', 'https://img.piku.co.kr/w/uploads/721FCA/a74e050844c9dde07de9018c64e36dc7.jpg', '강다니엘', '0.65%', '46.70%')])\n"
     ]
    }
   ],
   "source": [
    "NUM_CONTEXT = 48 # (2 * 24)\n",
    "NUM_QUERY = 7 # ( 2 * 4)\n",
    "\n",
    "sampled_results = sort_once_sample_shuffle_multiple_trials(datasets[DATASET_NAME], sort_key=SORT_KEY, reverse=True, \n",
    "                                                       sample_size=(NUM_CONTEXT + NUM_QUERY), trials=1)\n",
    "print(sampled_results[0][0])\n",
    "print(len(sampled_results[0][0]))\n",
    "print(sampled_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "torch.Size([48, 3, 224, 224])\n",
      "Context torch.Size([1, 48, 3, 224, 224]) \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "torch.Size([7, 3, 224, 224])\n",
      "Query torch.Size([1, 7, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# sampled_results Length: NUM_TRIALS, SAMPLES: NUM_SAMPLES\n",
    "context_scores = {}\n",
    "query_scores = {}\n",
    "\n",
    "vision_context = []\n",
    "for trial in sampled_results:\n",
    "    samples = []\n",
    "    for i, sample in enumerate(trial[1][0:NUM_CONTEXT]):\n",
    "        print(i)\n",
    "        x = image_processor(Image.open(\n",
    "            f'./Dataset00/Data00_{sample[0]}.jpg'\n",
    "        ))\n",
    "        samples.append(x)\n",
    "        context_scores[i] = sample[4]\n",
    "        \n",
    "    samples = torch.stack(samples, dim=0)\n",
    "    print(samples.shape)\n",
    "    vision_context.append(samples)\n",
    "\n",
    "vision_context = torch.stack(vision_context, dim=0)\n",
    "print(\"Context\", vision_context.shape, \"\\n\")\n",
    "\n",
    "\n",
    "vision_query = []\n",
    "for trial in sampled_results:\n",
    "    samples = []\n",
    "    for i, sample in enumerate(trial[1][NUM_CONTEXT:NUM_CONTEXT + NUM_QUERY + 1]):\n",
    "        print(i)\n",
    "        x = image_processor(Image.open(\n",
    "            f'./Dataset00/Data00_{sample[0]}.jpg'\n",
    "        ))\n",
    "        query_scores[i] = sample[4]\n",
    "        samples.append(x)\n",
    "    samples = torch.stack(samples, dim=0)\n",
    "    print(samples.shape)\n",
    "    vision_query.append(samples)\n",
    "vision_query = torch.stack(vision_query, dim=0)\n",
    "print(\"Query\", vision_query.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '46.33%',\n",
       " 1: '45.61%',\n",
       " 2: '52.35%',\n",
       " 3: '31.48%',\n",
       " 4: '47.87%',\n",
       " 5: '51.08%',\n",
       " 6: '25.48%',\n",
       " 7: '41.55%',\n",
       " 8: '31.97%',\n",
       " 9: '77.56%',\n",
       " 10: '59.02%',\n",
       " 11: '57.58%',\n",
       " 12: '36.56%',\n",
       " 13: '49.43%',\n",
       " 14: '59.95%',\n",
       " 15: '36.80%',\n",
       " 16: '39.86%',\n",
       " 17: '32.98%',\n",
       " 18: '42.93%',\n",
       " 19: '30.75%',\n",
       " 20: '57.93%',\n",
       " 21: '70.44%',\n",
       " 22: '67.55%',\n",
       " 23: '53.77%',\n",
       " 24: '42.15%',\n",
       " 25: '65.77%',\n",
       " 26: '16.98%',\n",
       " 27: '42.53%',\n",
       " 28: '27.71%',\n",
       " 29: '24.36%',\n",
       " 30: '64.76%',\n",
       " 31: '35.59%',\n",
       " 32: '49.81%',\n",
       " 33: '60.53%',\n",
       " 34: '34.69%',\n",
       " 35: '45.39%',\n",
       " 36: '69.69%',\n",
       " 37: '19.04%',\n",
       " 38: '44.85%',\n",
       " 39: '38.59%',\n",
       " 40: '61.76%',\n",
       " 41: '66.75%',\n",
       " 42: '42.36%',\n",
       " 43: '42.84%',\n",
       " 44: '43.66%',\n",
       " 45: '62.68%',\n",
       " 46: '39.31%',\n",
       " 47: '50.37%'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '60.53%',\n",
       " 1: '57.23%',\n",
       " 2: '38.21%',\n",
       " 3: '22.05%',\n",
       " 4: '28.60%',\n",
       " 5: '54.87%',\n",
       " 6: '46.70%'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['46.33%', '45.61%']\n",
      "['52.35%', '31.48%']\n",
      "['47.87%', '51.08%']\n",
      "['25.48%', '41.55%']\n",
      "['31.97%', '77.56%']\n",
      "['59.02%', '57.58%']\n",
      "['36.56%', '49.43%']\n",
      "['59.95%', '36.80%']\n",
      "['39.86%', '32.98%']\n",
      "['42.93%', '30.75%']\n",
      "['57.93%', '70.44%']\n",
      "['67.55%', '53.77%']\n",
      "['42.15%', '65.77%']\n",
      "['16.98%', '42.53%']\n",
      "['27.71%', '24.36%']\n",
      "['64.76%', '35.59%']\n",
      "['49.81%', '60.53%']\n",
      "['34.69%', '45.39%']\n",
      "['69.69%', '19.04%']\n",
      "['44.85%', '38.59%']\n",
      "['61.76%', '66.75%']\n",
      "['42.36%', '42.84%']\n",
      "['43.66%', '62.68%']\n",
      "['39.31%', '50.37%']\n",
      "['(A)', '(A)', '(B)', '(B)', '(B)', '(A)', '(B)', '(A)', '(A)', '(A)', '(B)', '(A)', '(B)', '(B)', '(A)', '(A)', '(B)', '(B)', '(A)', '(A)', '(B)', '(B)', '(B)', '(B)']\n"
     ]
    }
   ],
   "source": [
    "context_answer = []\n",
    "len_c = len(context_scores)\n",
    "\n",
    "for i in range(len_c // 2):\n",
    "    curr_ = list(context_scores.values())[i * 2: i * 2 + 2]\n",
    "    answer = '(B)'\n",
    "    if curr_[0] > curr_[1]:\n",
    "        answer = '(A)'\n",
    "    context_answer.append(answer)\n",
    "        \n",
    "    print(curr_)\n",
    "print(context_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['60.53%', '57.23%']\n",
      "['38.21%', '22.05%']\n",
      "['28.60%', '54.87%']\n",
      "['(A)', '(A)', '(B)']\n"
     ]
    }
   ],
   "source": [
    "query_answer = []\n",
    "len_q = len(query_scores)\n",
    "\n",
    "for i in range(len_q // 2):\n",
    "    curr_ = list(query_scores.values())[i * 2: i * 2 + 2]\n",
    "    answer = '(B)'\n",
    "    if curr_[0] > curr_[1]:\n",
    "        answer = '(A)'\n",
    "    query_answer.append(answer)\n",
    "        \n",
    "    print(curr_)\n",
    "print(query_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_score_answer(scores):\n",
    "    curr_answer = []\n",
    "    len_ = len(scores)\n",
    "    \n",
    "    for i in range(len_ // 2):\n",
    "        curr_ = list(scores.values())[i * 2: i * 2 + 2]\n",
    "        answer = '(B)'\n",
    "        if curr_[0] > curr_[1]:\n",
    "            answer = '(A)'\n",
    "        curr_answer.append(answer)\n",
    "            \n",
    "        print(curr_)\n",
    "    print(curr_answer)\n",
    "    return curr_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|><|endofchunk|> \n",
      "\n",
      "Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer:\n"
     ]
    }
   ],
   "source": [
    "task_prompt_text = ''\n",
    "question_prompt = 'Choose the more aesthetic image. Options:'\n",
    "len_c = len(context_scores)\n",
    "len_q = len(query_scores)\n",
    "\n",
    "\n",
    "context_text = task_prompt_text + ''.join([\n",
    "    question_prompt + f\"(A) <image> \b(B) <image>. Answer: {context_answer[i]} <|endofchunk|>\"\n",
    "    for i in range(len_c // 2)\n",
    "])\n",
    "context_text = context_text + f\"<|endofchunk|>\"\n",
    "print(context_text, \"\\n\")\n",
    "\n",
    "queries_text = [\n",
    "    question_prompt + f\"(A) <image> \b(B) <image>. Answer:\"\n",
    "    for _ in range(NUM_TRIALS)\n",
    "]\n",
    "\n",
    "print(queries_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 48, 1, 3, 224, 224]), torch.Size([1, 7, 1, 3, 224, 224]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vision_context[None, 0, :].unsqueeze(2)[:, :, :].shape, vision_query[:, :, :].unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_QUERY // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(vision_context, vision_query, context_text, queries_text, query_answer, num):\n",
    "    print(f\"Query answer: {query_answer}\")\n",
    "\n",
    "    \"\"\"\n",
    "    Step 4: Generate text\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        context_len = len(context_text)\n",
    "        for q_i in range(NUM_QUERY // 2):\n",
    "            start = time.time()\n",
    "            print(f\"Start time: {start}\")\n",
    "            vision_x = torch.concat([vision_context[None, 0, :].unsqueeze(2)[:, :num, :],  vision_query[:, q_i * 2: q_i * 2 + 2, :].unsqueeze(2)], dim=1)\n",
    "            lang_x = tokenizer(\n",
    "                [context_text + queries_text[0] for _ in range(1)], \n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            generated_text = model.generate(\n",
    "                vision_x=vision_x,\n",
    "                lang_x=lang_x[\"input_ids\"],\n",
    "                attention_mask=lang_x[\"attention_mask\"],\n",
    "                max_new_tokens=3,\n",
    "                num_beams=3,\n",
    "            )\n",
    "    \n",
    "            generated = tokenizer.decode(generated_text[0])\n",
    "            print(\"Context: \", generated[:context_len])\n",
    "            print(\"Generated text: \", generated[context_len:])\n",
    "            end = time.time()\n",
    "            print(f\"Time {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 7, 3, 224, 224])\n",
      "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "white_ = torch.ones([3, 224, 224])\n",
    "print(white_.shape)\n",
    "# Original Query \n",
    "# ['60.53%', '57.23%']\n",
    "# ['38.21%', '22.05%']\n",
    "# ['28.60%', '54.87%']\n",
    "# ['(A)', '(A)', '(B)']\n",
    "\n",
    "vision_query_new = vision_query\n",
    "choosen = [ 0, 2, 5] \n",
    "for i in choosen:\n",
    "    vision_query_new[0, i, :] = white_\n",
    "print(vision_query_new.shape)\n",
    "print(vision_query_new[0, 0])\n",
    "vision_query_new.shape\n",
    "new_answer = ['(B)', '(B)', '(A)']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query answer: ['(B)', '(B)', '(A)']\n",
      "Start time: 1701692063.1972709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jisoo/.conda/envs/dev/lib/python3.8/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|><|endofchunk|>\n",
      "Generated text:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A)\n",
      "Time 186.3488802909851\n",
      "Start time: 1701692249.5461752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|><|endofchunk|>\n",
      "Generated text:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A)\n",
      "Time 197.57523560523987\n",
      "Start time: 1701692447.1214335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|><|endofchunk|>\n",
      "Generated text:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A)\n",
      "Time 197.9806683063507\n"
     ]
    }
   ],
   "source": [
    " predict(vision_context, vision_query_new, context_text, queries_text, new_answer, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query answer: ['(A)', '(A)', '(B)']\n",
      "Start time: 1701692645.1152763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|><|endofchunk|>\n",
      "Generated text:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A)\n",
      "Time 211.0722405910492\n",
      "Start time: 1701692856.1875386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|><|endofchunk|>\n",
      "Generated text:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A)\n",
      "Time 230.60411143302917\n",
      "Start time: 1701693086.7916646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|><|endofchunk|>\n",
      "Generated text:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A)\n",
      "Time 229.5096230506897\n"
     ]
    }
   ],
   "source": [
    " predict(vision_context, vision_query, context_text, queries_text, query_answer, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 48, 3, 224, 224])\n",
      "0\n",
      "3\n",
      "5\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "15\n",
      "16\n",
      "18\n",
      "21\n",
      "22\n",
      "25\n",
      "26\n",
      "28\n",
      "31\n",
      "33\n",
      "34\n",
      "37\n",
      "39\n",
      "41\n",
      "42\n",
      "44\n",
      "46\n",
      "['0.0%', '45.61%']\n",
      "['52.35%', '0.0%']\n",
      "['47.87%', '0.0%']\n",
      "['0.0%', '41.55%']\n",
      "['0.0%', '77.56%']\n",
      "['0.0%', '57.58%']\n",
      "['0.0%', '49.43%']\n",
      "['59.95%', '0.0%']\n",
      "['0.0%', '32.98%']\n",
      "['0.0%', '30.75%']\n",
      "['57.93%', '0.0%']\n",
      "['0.0%', '53.77%']\n",
      "['42.15%', '0.0%']\n",
      "['0.0%', '42.53%']\n",
      "['0.0%', '24.36%']\n",
      "['64.76%', '0.0%']\n",
      "['49.81%', '0.0%']\n",
      "['0.0%', '45.39%']\n",
      "['69.69%', '0.0%']\n",
      "['44.85%', '0.0%']\n",
      "['61.76%', '0.0%']\n",
      "['0.0%', '42.84%']\n",
      "['0.0%', '62.68%']\n",
      "['0.0%', '50.37%']\n",
      "['(B)', '(A)', '(A)', '(B)', '(B)', '(B)', '(B)', '(A)', '(B)', '(B)', '(A)', '(B)', '(A)', '(B)', '(B)', '(A)', '(A)', '(B)', '(A)', '(A)', '(A)', '(B)', '(B)', '(B)']\n"
     ]
    }
   ],
   "source": [
    "white_ = torch.ones([3, 224, 224])\n",
    "print(white_.shape)\n",
    "# Original Query \n",
    "# ['60.53%', '57.23%']\n",
    "# ['38.21%', '22.05%']\n",
    "# ['28.60%', '54.87%']\n",
    "# ['(A)', '(A)', '(B)']\n",
    "\n",
    "new_answer = []\n",
    "vision_context_new = vision_context\n",
    "context_scores_new = context_scores\n",
    "print(vision_context_new.shape)\n",
    "for i in range(vision_context.shape[1]// 2):\n",
    "    curr = random.choice([i*2, i*2 + 1])\n",
    "    vision_context_new[0, curr, :] = white_\n",
    "    context_scores_new[curr] = '0.0%'\n",
    "    print(curr)\n",
    "\n",
    "context_answer_new = []\n",
    "len_c = len(context_scores_new)\n",
    "\n",
    "for i in range(len_c // 2):\n",
    "    curr_ = list(context_scores_new.values())[i * 2: i * 2 + 2]\n",
    "    answer = '(B)'\n",
    "    if curr_[0] > curr_[1]:\n",
    "        answer = '(A)'\n",
    "    context_answer_new.append(answer)\n",
    "        \n",
    "    print(curr_)\n",
    "print(context_answer_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|><|endofchunk|> \n",
      "\n",
      "Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer:\n"
     ]
    }
   ],
   "source": [
    "task_prompt_text = ''\n",
    "question_prompt = 'Choose the more aesthetic image. Options:'\n",
    "len_c = len(context_scores)\n",
    "len_q = len(query_scores)\n",
    "\n",
    "\n",
    "context_text = task_prompt_text + ''.join([\n",
    "    question_prompt + f\"(A) <image> \b(B) <image>. Answer: {context_answer_new[i]} <|endofchunk|>\"\n",
    "    for i in range(len_c // 2)\n",
    "])\n",
    "context_text = context_text + f\"<|endofchunk|>\"\n",
    "print(context_text, \"\\n\")\n",
    "\n",
    "queries_text = [\n",
    "    question_prompt + f\"(A) <image> \b(B) <image>. Answer:\"\n",
    "    for _ in range(NUM_TRIALS)\n",
    "]\n",
    "\n",
    "print(queries_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query answer: ['(B)', '(B)', '(A)']\n",
      "Start time: 1701693849.3406339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|><|endofchunk|>\n",
      "Generated text:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A)\n",
      "Time 226.13598132133484\n",
      "Start time: 1701694075.4766266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|><|endofchunk|>\n",
      "Generated text:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A)\n",
      "Time 223.60786080360413\n",
      "Start time: 1701694299.0844991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|><|endofchunk|>\n",
      "Generated text:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A)\n",
      "Time 223.17199873924255\n"
     ]
    }
   ],
   "source": [
    " predict(vision_context_new, vision_query_new, context_text, queries_text, new_answer, 48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score evaluated based on the final rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "torch.Size([48, 3, 224, 224])\n",
      "Context torch.Size([1, 48, 3, 224, 224]) \n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "torch.Size([7, 3, 224, 224])\n",
      "Query torch.Size([1, 7, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "3\n",
    "\n",
    "# sampled_results Length: NUM_TRIALS, SAMPLES: NUM_SAMPLES\n",
    "context_scores = {}\n",
    "query_scores = {}\n",
    "\n",
    "vision_context = []\n",
    "for trial in sampled_results:\n",
    "    samples = []\n",
    "    for i, sample in enumerate(trial[1][0:NUM_CONTEXT]):\n",
    "        print(i)\n",
    "        x = image_processor(Image.open(\n",
    "            f'./Dataset00/Data00_{sample[0]}.jpg'\n",
    "        ))\n",
    "        samples.append(x)\n",
    "        context_scores[i] = sample[3]\n",
    "        \n",
    "    samples = torch.stack(samples, dim=0)\n",
    "    print(samples.shape)\n",
    "    vision_context.append(samples)\n",
    "\n",
    "vision_context = torch.stack(vision_context, dim=0)\n",
    "print(\"Context\", vision_context.shape, \"\\n\")\n",
    "\n",
    "\n",
    "vision_query = []\n",
    "for trial in sampled_results:\n",
    "    samples = []\n",
    "    for i, sample in enumerate(trial[1][NUM_CONTEXT:NUM_CONTEXT + NUM_QUERY + 1]):\n",
    "        print(i)\n",
    "        x = image_processor(Image.open(\n",
    "            f'./Dataset00/Data00_{sample[0]}.jpg'\n",
    "        ))\n",
    "        query_scores[i] = sample[3]\n",
    "        samples.append(x)\n",
    "    samples = torch.stack(samples, dim=0)\n",
    "    print(samples.shape)\n",
    "    vision_query.append(samples)\n",
    "vision_query = torch.stack(vision_query, dim=0)\n",
    "print(\"Query\", vision_query.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.38%', '0.98%']\n",
      "['0.35%', '0.04%']\n",
      "['0.47%', '0.45%']\n",
      "['0.13%', '0.30%']\n",
      "['0.02%', '11.31%']\n",
      "['1.13%', '1.86%']\n",
      "['0.06%', '0.50%']\n",
      "['1.36%', '0.07%']\n",
      "['0.19%', '0.11%']\n",
      "['0.34%', '0.15%']\n",
      "['1.21%', '4.51%']\n",
      "['3.68%', '1.07%']\n",
      "['0.11%', '2.75%']\n",
      "['0.04%', '0.31%']\n",
      "['0.15%', '0.06%']\n",
      "['3.65%', '0.15%']\n",
      "['0.65%', '2.15%']\n",
      "['0.02%', '0.08%']\n",
      "['4.20%', '0.04%']\n",
      "['0.21%', '0.22%']\n",
      "['2.93%', '3.17%']\n",
      "['0.24%', '0.13%']\n",
      "['0.21%', '2.28%']\n",
      "['0.11%', '1.06%']\n",
      "['(B)', '(A)', '(A)', '(B)', '(B)', '(B)', '(B)', '(A)', '(A)', '(A)', '(B)', '(A)', '(B)', '(B)', '(A)', '(A)', '(B)', '(B)', '(A)', '(B)', '(B)', '(A)', '(B)', '(B)']\n",
      "['1.29%', '1.38%']\n",
      "['0.30%', '0.02%']\n",
      "['0.23%', '1.42%']\n",
      "['(B)', '(A)', '(B)']\n"
     ]
    }
   ],
   "source": [
    "context_answer = []\n",
    "len_c = len(context_scores)\n",
    "\n",
    "for i in range(len_c // 2):\n",
    "    curr_ = list(context_scores.values())[i * 2: i * 2 + 2]\n",
    "    answer = '(B)'\n",
    "    if curr_[0] > curr_[1]:\n",
    "        answer = '(A)'\n",
    "    context_answer.append(answer)\n",
    "        \n",
    "    print(curr_)\n",
    "print(context_answer)\n",
    "\n",
    "query_answer = []\n",
    "len_q = len(query_scores)\n",
    "\n",
    "for i in range(len_q // 2):\n",
    "    curr_ = list(query_scores.values())[i * 2: i * 2 + 2]\n",
    "    answer = '(B)'\n",
    "    if curr_[0] > curr_[1]:\n",
    "        answer = '(A)'\n",
    "    query_answer.append(answer)\n",
    "        \n",
    "    print(curr_)\n",
    "print(query_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|><|endofchunk|> \n",
      "\n",
      "Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer:\n"
     ]
    }
   ],
   "source": [
    "task_prompt_text = ''\n",
    "question_prompt = 'Choose the more aesthetic image. Options:'\n",
    "len_c = len(context_scores)\n",
    "len_q = len(query_scores)\n",
    "\n",
    "\n",
    "context_text = task_prompt_text + ''.join([\n",
    "    question_prompt + f\"(A) <image> \b(B) <image>. Answer: {context_answer[i]} <|endofchunk|>\"\n",
    "    for i in range(len_c // 2)\n",
    "])\n",
    "context_text = context_text + f\"<|endofchunk|>\"\n",
    "print(context_text, \"\\n\")\n",
    "\n",
    "queries_text = [\n",
    "    question_prompt + f\"(A) <image> \b(B) <image>. Answer:\"\n",
    "    for _ in range(NUM_TRIALS)\n",
    "]\n",
    "\n",
    "print(queries_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query answer: ['(B)', '(A)', '(B)']\n",
      "Start time: 1701694527.374507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|><|endofchunk|>\n",
      "Generated text:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A)\n",
      "Time 223.96712589263916\n",
      "Start time: 1701694751.3416445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|><|endofchunk|>\n",
      "Generated text:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A)\n",
      "Time 224.85135984420776\n",
      "Start time: 1701694976.1930158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|><|endofchunk|>\n",
      "Generated text:  Choose the more aesthetic image. Options:(A) <image>(B) <image>. Answer: (A)\n",
      "Time 223.91530203819275\n"
     ]
    }
   ],
   "source": [
    " predict(vision_context, vision_query, context_text, queries_text, query_answer, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|><|endofchunk|> \n",
      "\n",
      "Which image is better?. Options:(A) <image>(B) <image>. Answer:\n"
     ]
    }
   ],
   "source": [
    "task_prompt_text = ''\n",
    "question_prompt = 'Which image is better?. Options:'\n",
    "len_c = len(context_scores)\n",
    "len_q = len(query_scores)\n",
    "\n",
    "\n",
    "context_text = task_prompt_text + ''.join([\n",
    "    question_prompt + f\"(A) <image> \b(B) <image>. Answer: {context_answer[i]} <|endofchunk|>\"\n",
    "    for i in range(len_c // 2)\n",
    "])\n",
    "context_text = context_text + f\"<|endofchunk|>\"\n",
    "print(context_text, \"\\n\")\n",
    "\n",
    "queries_text = [\n",
    "    question_prompt + f\"(A) <image> \b(B) <image>. Answer:\"\n",
    "    for _ in range(NUM_TRIALS)\n",
    "]\n",
    "\n",
    "print(queries_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query answer: ['(B)', '(A)', '(B)']\n",
      "Start time: 1701695200.1250484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|><|endofchunk|>\n",
      "Generated text:  Which image is better?. Options:(A) <image>(B) <image>. Answer: (A)\n",
      "Time 188.1906177997589\n",
      "Start time: 1701695388.315679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (A) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|>Which image is better?. Options:(A) <image>(B) <image>. Answer: (B) <|endofchunk|><|endofchunk|>\n",
      "Generated text:  Which image is better?. Options:(A) <image>(B) <image>. Answer: (A)\n",
      "Time 193.49916195869446\n",
      "Start time: 1701695581.8148534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50277 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    " predict(vision_context, vision_query, context_text, queries_text, query_answer, 48)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
